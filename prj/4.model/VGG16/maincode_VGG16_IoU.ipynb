{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from plotly import __version__\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# import cufflinks as cf\n",
    "# cf.go_offline()\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from numpy import set_printoptions\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ecc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622aee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = \"../../exps\"\n",
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f\"{exps_dir}/feature1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d162d6",
   "metadata": {},
   "source": [
    "* kiểm tra và tạo các thư mục (nếu chưa có)\n",
    "* tập test 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7e092",
   "metadata": {},
   "source": [
    "# 5. Xây dựng và đánh giá mô hình học sâu Neutual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bdb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "# from mlxtend.classifier import StackingClassifier\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from scipy.stats import uniform\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e81211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{exps_dir}/feature1/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acebdcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Định nghĩa không gian siêu tham số\n",
    "param_dist = {'C': uniform(0.1, 10),\n",
    "              'kernel': ['linear', 'rbf', 'poly'],\n",
    "              'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 7))}\n",
    "\n",
    "# Khởi tạo mô hình SVM\n",
    "svm_model = SVC()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search = RandomizedSearchCV(svm_model, param_distributions=param_dist, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình SVM tốt nhất\n",
    "print(\"Best SVM Hyperparameters:\")\n",
    "print(random_search.best_params_)\n",
    "C=random_search.best_params_['C']\n",
    "gamma=random_search.best_params_['gamma']\n",
    "kernel=random_search.best_params_['kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Định nghĩa không gian siêu tham số\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_rf = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_rf.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Random Forest tốt nhất\n",
    "print(\"Best Random Forest Hyperparameters:\")\n",
    "print(random_search_rf.best_params_)\n",
    "n_estimators=random_search_rf.best_params_['n_estimators']\n",
    "max_depth=random_search_rf.best_params_['max_depth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927be684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Định nghĩa không gian siêu tham số cho Gradient Boosting\n",
    "param_dist_gb = {'n_estimators': randint(50, 200),\n",
    "                 'learning_rate': uniform(0.01, 0.1),\n",
    "                 'max_depth': randint(3, 10),\n",
    "                 'subsample': uniform(0.6, 0.4)}\n",
    "\n",
    "# Khởi tạo mô hình Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_gb = RandomizedSearchCV(gb_model, param_distributions=param_dist_gb, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_gb.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Gradient Boosting tốt nhất\n",
    "print(\"Best Gradient Boosting Hyperparameters:\")\n",
    "print(random_search_gb.best_params_)\n",
    "best_gb_model = random_search_gb.best_estimator_\n",
    "max_depthgb=random_search_gb.best_params_['max_depth']\n",
    "learning_rate=random_search_gb.best_params_['learning_rate']\n",
    "n_estimatorsgb=random_search_gb.best_params_['n_estimators']\n",
    "subsample=random_search_gb.best_params_['subsample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a70978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Định nghĩa không gian siêu tham số cho Decision Tree\n",
    "param_dist_dt = {'criterion': ['gini', 'entropy'],\n",
    "                 'splitter': ['best', 'random'],\n",
    "                 'max_depth': randint(3, 10),\n",
    "                 'min_samples_split': randint(2, 20),\n",
    "                 'min_samples_leaf': randint(1, 20)}\n",
    "\n",
    "# Khởi tạo mô hình Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_dt = RandomizedSearchCV(dt_model, param_distributions=param_dist_dt, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_dt.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Decision Tree tốt nhất\n",
    "print(\"Best Decision Tree Hyperparameters:\")\n",
    "print(random_search_dt.best_params_)\n",
    "best_dt_model = random_search_dt.best_estimator_\n",
    "criterion=random_search_dt.best_params_['criterion']\n",
    "max_depthdt=random_search_dt.best_params_['max_depth']\n",
    "min_samples_leaf=random_search_dt.best_params_['min_samples_leaf']\n",
    "splitter=random_search_dt.best_params_['splitter']\n",
    "min_samples_split=random_search_dt.best_params_['min_samples_split']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6de984",
   "metadata": {},
   "source": [
    "#### * Xây dựng model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bffefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import to_categorical\n",
    "#y_train = to_categorical(y_train, num_classes=2)\n",
    "#y_test = to_categorical(y_test, num_classes=2)\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "def f1_loss(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='micro')\n",
    "    return 1 - f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c90d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "    pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "    loss = -tf.reduce_mean(alpha * tf.pow(1.0 - pt, gamma) * tf.math.log(pt))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3dbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def iou_loss(y_true, y_pred):\n",
    "    # Tính toán intersection và union\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    \n",
    "    # Tính toán IoU\n",
    "    iou = K.mean((intersection + 1e-6) / (union + 1e-6))\n",
    "    \n",
    "    # Chuyển đổi IoU thành mất mát IoU\n",
    "    iou_loss = 1 - iou\n",
    "    \n",
    "    return iou_loss\n",
    "\n",
    "# Sử dụng hàm mất mát iou_loss cho model.compile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "    return 1 - (numerator + 1) / (denominator + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "lr=0.0001\n",
    "\n",
    "def build_model(hp):\n",
    "    input_shape =(42,1)\n",
    "    x_input = Input(shape=input_shape)\n",
    "    dense_units = hp.Int('dense_units', min_value=128, max_value=4096, step=128)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv1D(hp.Int('filters1', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block1_conv1')(x_input)\n",
    "    x = Conv1D(hp.Int('filters1', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(hp.Int('filters2', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv1D(hp.Int('filters2', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(hp.Int('filters3', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(hp.Int('filters3', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv1D(hp.Int('filters3', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(hp.Int('filters4', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(hp.Int('filters4', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv1D(hp.Int('filters4', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv1D(hp.Int('filters5', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv1D(hp.Int('filters5', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv1D(hp.Int('filters5', min_value=32, max_value=512, step=32), hp.Int('kernel_size', min_value=2, max_value=5, step=1), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block5_pool')(x)\n",
    "    \n",
    "    # x = Flatten(name='flatten')(x)\n",
    "    # x = Dense(dense_units, activation='relu', name='fc1')(x)\n",
    "    # x = Dense(dense_units, activation='relu', name='fc2')(x)\n",
    "    # x = Dense(1, activation='sigmoid', name='predictions')(x)  # Sigmoid for binary classification\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    #x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(2, activation='softmax', name='predictions')(x)  # Sigmoid for binary classification\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(x_input, x, name='vgg16')\n",
    "    # model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # model.compile(optimizer=Adam(lr=learning_rate), loss=f1_loss, metrics=['accuracy'])\n",
    "    # model.compile(optimizer=Adam(lr=learning_rate), loss=focal_loss, metrics=['accuracy'])\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=dice_loss, metrics=['accuracy'])\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=iou_loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    min_lr=0.000001,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Tạo đối tượng RandomSearch tuner\n",
    "tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=10,executions_per_trial=10,directory = \"VGG16\")\n",
    "\n",
    "# Tìm kiếm tham số tốt nhất\n",
    "tuner.search(x_train, y_train, epochs=600, validation_data=(x_test, y_test),callbacks=[early_stopping,lr_scheduler])\n",
    "\n",
    "# Lấy mô hình tốt nhất\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials = tuner.oracle.get_best_trials(1)[0].hyperparameters.values\n",
    "best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351dafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(x_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1453ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Đánh giá độ chính xác\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Hiển thị báo cáo phân loại\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions,labels=[1,0]))\n",
    "\n",
    "# # Hiển thị ma trận nhầm lẫn\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred,labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_test, predictions,labels=[1,0])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=[1,0], yticklabels=[1,0])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f443f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_test, predictions,ax,name='model'):    \n",
    "    # Tính toán FPR và TPR từ decision function\n",
    "    fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "    \n",
    "    # Tính diện tích dưới đường cong ROC (AUC)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Vẽ đường cong ROC\n",
    "    ax.plot(fpr, tpr, lw=4, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    ax.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=12, weight='bold')  # Đặt kích thước và độ dày cho nhãn trục x\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=12, weight='bold')   # Đặt kích thước và độ dày cho nhãn trục y\n",
    "    ax.set_title(f'ROC of {name}',fontsize=20, weight='bold')  # Đặt kích thước và độ dày cho tiêu đề\n",
    "    ax.legend(loc=\"lower right\", prop={'size': 12, 'weight': 'bold'})  # Đặt kích thước và độ dày cho chú thích\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "plot_roc_curve(y_test,predictions,axes)\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(prediction):\n",
    "    prediction = (prediction > 0.5).astype(int)\n",
    "    if isinstance(prediction, (np.ndarray, pd.Series)):\n",
    "        prediction = prediction.item()  # Hoặc sử dụng prediction[0] hoặc prediction.iloc[0]\n",
    "    if prediction==1:\n",
    "        return \"Y\"\n",
    "    else:\n",
    "        return \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "solandung=0\n",
    "hopdonggianlan=0\n",
    "for indx in range(len(x_test)):\n",
    "    y_predict = predictions\n",
    "    #print(y_predict[0][0])\n",
    "    Y_check = check_result(y_test.iloc[indx])\n",
    "    print('True:', Y_check)\n",
    "    print('Predicted:', check_result(y_predict[indx]))\n",
    "    print(\"----------------------------\")\n",
    "    if Y_check==check_result(y_predict[indx]):\n",
    "        solandung+=1\n",
    "        if Y_check=='Y':\n",
    "            hopdonggianlan+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef996354",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Số lần dự đoán đúng: {solandung} chiếm khoảng {(solandung/len(x_test))*100}% tổng lần dự đoán\")\n",
    "print(f\"Số hợp đồng gian lận trong lần kiểm tra: {hopdonggianlan} chiếm khoảng {(hopdonggianlan/len(y_test[y_test['fraud_reported']==1]))*100}% so với thực tế\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93feaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e9491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
