{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8c11c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from numpy import set_printoptions\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622aee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = \"../../exps\"\n",
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f\"{exps_dir}/feature1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d162d6",
   "metadata": {},
   "source": [
    "* kiểm tra và tạo các thư mục (nếu chưa có)\n",
    "* tập test 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7e092",
   "metadata": {},
   "source": [
    "# 5. Xây dựng và đánh giá mô hình học sâu Neutual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e81211d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6555772994129159, 1: 2.106918238993711}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "# df=pd.read_excel(f'{save_dir}/df_minmax_labelencode.xlsx')\n",
    "# df=train_test_split(df,random_state=42,test_size=0.33)\n",
    "class_weights_dict=dict(np.load(f'{exps_dir}/feature1/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f8e2c",
   "metadata": {},
   "source": [
    "* Sử dụng thư viện **imbalanced-learn** để thực hiện Oversampling bằng phương pháp **SMOTE (Synthetic Minority Over-sampling Technique).** \n",
    "\n",
    "#### Giải thích:\n",
    "* Vì tập dữ liệu của nhóm là tập dữ liệu phân loại không cân bằng => **SMOTE** được sử dụng để tăng cường dữ liệu trong trường hợp mẫu của lớp thiểu số (minority class) quá ít so với lớp đa số (majority class), giúp cân bằng dữ liệu và cải thiện hiệu suất của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22c37a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 39) (1022, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc05d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Thêm các lớp ẩn\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Lớp đầu ra với activation function 'sigmoid' cho bài toán phân lớp nhị phân\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55c252bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assume X là ma trận đặc trưng, y là nhãn\n",
    "\n",
    "# Sử dụng SMOTE và RandomUnderSampler để cân bằng dữ liệu\n",
    "over_sampler = SMOTE(sampling_strategy=0.1)  # Điều chỉnh sampling_strategy nếu cần\n",
    "# under_sampler = RandomUnderSampler(sampling_strategy=1)  # Điều chỉnh sampling_strategy nếu cần\n",
    "\n",
    "# Sử dụng mô hình Random Forest làm mô hình cơ bản\n",
    "base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Tạo pipeline kết hợp SMOTE, RandomUnderSampler và mô hình cơ bản\n",
    "model = Pipeline([\n",
    "    ('over', over_sampler),\n",
    "    ('under', under_sampler),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Huấn luyện mô hình trên dữ liệu đã được cân bằng\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991563c7",
   "metadata": {},
   "source": [
    "### Giải thích:\n",
    "   Nhóm sử dụng thư viện TensorFlow và Keras xây dựng một mô hình mạng nơ-ron sử dụng Sequential API:\n",
    "   \n",
    "   1. Đầu tiên, tạo mô hình Sử dụng mô hình tuần tự **Sequential**\n",
    "   2. Sau đó, thêm các lớp Dense với hàm kích hoạt **'relu'**. Nhóm sử dụng **Dropout** tại mỗi tầng để ngẫu nhiên \"tắt\" khoảng 50% số nơ-ron tại tầng đó trong quá trình huấn luyện, ngăn chặn hiện tượng quá mức học (overfitting).\n",
    "   3. Thêm lớp output với hàm kích hoạt 'tanh'. Hàm **'tanh'** chuyển đổi mỗi giá trị đầu ra từ khoảng (-∞, ∞) về khoảng (-1, 1).\n",
    "   4. Compile mô hình: \n",
    "      * loss=**binary_crossentropy** được sử dụng vì đây là một bài toán phân loại nhị phân. \n",
    "      * optimizer=**adam** là một thuật toán tối ưu hóa phổ biến. \n",
    "      * metric=**'accuracy'**, Theo dõi độ chính xác của mô hình trong quá trình huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01c44960",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [early_stopping,lr_scheduler]\n\u001b[0;32m     20\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmotion_weights.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\imblearn\\pipeline.py:293\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m    292\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 293\u001b[0m Xt, yt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\imblearn\\pipeline.py:250\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    240\u001b[0m     X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    241\u001b[0m         cloned_transformer,\n\u001b[0;32m    242\u001b[0m         X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    248\u001b[0m     )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cloned_transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_resample\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 250\u001b[0m     X, y, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_resample_one_cached(\n\u001b[0;32m    251\u001b[0m         cloned_transformer,\n\u001b[0;32m    252\u001b[0m         X,\n\u001b[0;32m    253\u001b[0m         y,\n\u001b[0;32m    254\u001b[0m         message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    255\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\imblearn\\pipeline.py:422\u001b[0m, in \u001b[0;36m_fit_resample_one\u001b[1;34m(sampler, X, y, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_resample_one\u001b[39m(sampler, X, y, message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m--> 422\u001b[0m         X_res, y_res \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39mfit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m X_res, y_res, sampler\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py:108\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_sampling_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampling_type\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\imblearn\\utils\\_validation.py:550\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sampling_strategy \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m sampling_strategy \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    545\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_strategy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a float, it should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the range (0, 1]. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    547\u001b[0m         )\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m--> 550\u001b[0m             \u001b[43m_sampling_strategy_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    551\u001b[0m         )\n\u001b[0;32m    552\u001b[0m     )\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(sampling_strategy):\n\u001b[0;32m    554\u001b[0m     sampling_strategy_ \u001b[38;5;241m=\u001b[39m sampling_strategy(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\imblearn\\utils\\_validation.py:389\u001b[0m, in \u001b[0;36m_sampling_strategy_float\u001b[1;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[0;32m    383\u001b[0m     sampling_strategy_ \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    384\u001b[0m         key: \u001b[38;5;28mint\u001b[39m(n_sample_majority \u001b[38;5;241m*\u001b[39m sampling_strategy \u001b[38;5;241m-\u001b[39m value)\n\u001b[0;32m    385\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m target_stats\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m class_majority\n\u001b[0;32m    387\u001b[0m     }\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m([n_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_samples \u001b[38;5;129;01min\u001b[39;00m sampling_strategy_\u001b[38;5;241m.\u001b[39mvalues()]):\n\u001b[1;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe specified ratio required to remove samples \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the minority class while trying to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate new samples. Please increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    393\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mratio.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    394\u001b[0m         )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    396\u001b[0m     n_sample_minority \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(target_stats\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[1;31mValueError\u001b[0m: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio."
     ]
    }
   ],
   "source": [
    "\n",
    "earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=11,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping,lr_scheduler]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = \"Emotion_weights.hdf5\", verbose = 1, save_best_only=True)\n",
    "\n",
    "model.fit(x_train,y=y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3f355",
   "metadata": {},
   "source": [
    "### Note:\n",
    "   #### 1. Early Stopping:\n",
    "   * **monitor='val_accuracy'**: Đây là đại lượng mà quá trình Early Stopping sẽ theo dõi. Trong trường hợp này, nó sẽ kiểm tra độ chính xác trên tập validation.\n",
    "   * **min_delta=0.00005**: Số lượng thay đổi nhỏ nhất giữa hai epoch để coi là có sự cải thiện. Nếu không có sự cải thiện lớn hơn min_delta sau số lượng epoch 'patience', quá trình huấn luyện sẽ dừng lại.\n",
    "   * **patience=11**: Số epoch mà mô hình có thể không cải thiện trước khi quá trình Early Stopping được kích hoạt.\n",
    "   * **verbose=1**: Hiển thị thông báo khi quá trình Early Stopping được kích hoạt.\n",
    "   * **restore_best_weights=True**: Khôi phục trọng số của mô hình tại epoch có độ chính xác cao nhất trên tập validation.\n",
    "    \n",
    "   #### 2. Learning Rate Scheduler (ReduceLROnPlateau):\n",
    "   * **monitor='val_accuracy'**: Đại lượng mà Learning Rate Scheduler sẽ theo dõi, cũng là độ chính xác trên tập validation.\n",
    "   * **factor=0.5**: Hệ số giảm learning rate. Khi được kích hoạt (sau 'patience' epochs mà không có cải thiện), learning rate sẽ được giảm đi một lượng bằng factor.\n",
    "   * **patience=7**: Số epoch mà mô hình có thể không cải thiện trước khi learning rate được giảm.\n",
    "   * **min_lr=0.00001**: Giới hạn dưới cho learning rate sau khi được giảm. Không bao giờ giảm dưới giá trị này.\n",
    "   * **verbose=1**: Hiển thị thông báo khi quá trình giảm learning rate được kích hoạt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec9d49",
   "metadata": {},
   "source": [
    "### Giải thích:\n",
    "   Nhóm thực hiện quá trình huấn luyện mô hình máy học với **model.fit**:\n",
    "   \n",
    "   * **x=x_train, y=y_train:** Dữ liệu đầu vào và nhãn cho quá trình đào tạo.\n",
    "   * **validation_data=(x_test,y_test):** Dữ liệu kiểm tra.\n",
    "   * **class_weight=class_weights_dict:** Trọng số lớp được áp dụng cho cân bằng lớp. (-> Vì tập dữ liệu mất cân bằng lớp)\n",
    "   * Kích thước batch là **batch_size=128.** \n",
    "   * Số lượng epochs là **epochs=600.** \n",
    "   * Nhóm sử dụng **callbacks = [early_stopping,lr_scheduler]** để đảm bảo rằng mô hình được lưu lại tại những điểm có độ chính xác tốt nhất trên tập kiểm tra và đồng thời ngừng sớm nếu không có sự cải thiện đáng kể. Bên cạnh đó, giảm learning rate giúp mô hình hội tụ chậm hơn và tránh việc vượt qua điểm tối ưu toàn cục."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb329d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5ac75a",
   "metadata": {},
   "source": [
    "#### Biểu đồ thể hiện loss và accuracy\n",
    "\n",
    "   * Hàm loss biểu thị mức độ lỗi của mô hình trong quá trình học tập\n",
    "   * Hàm accuracy biểu thị mức độ chính xác của mô hình trong việc dự đoán các dữ liệu trong tập kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07132b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(x_test)\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f218b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886a5e9",
   "metadata": {},
   "source": [
    "### Nhận xét\n",
    "\n",
    "   * Ta thấy **accuracy: 0.74**. Đây là tỷ lệ mẫu được dự đoán đúng trên tổng số mẫu. Tuy nhiên, vì tập dữ liệu của nhóm mất cân bằng lớp (lớp 0 có 239 mẫu, trong khi lớp 1 (gian lận) chỉ có 85 mẫu), Accuracy có thể không phản ánh chính xác vì mô hình có thể dự đoán một lớp nhiều hơn.\n",
    "   \n",
    "   * Các chỉ số **precision, recall, f1-score của lớp 1 đều =0.00**, Điều này có nghĩa là mô hình không tìm thấy dự đoán đúng cho lớp gian lận, không đạt được hiệu suất tốt trên lớp ít xuất hiện này. => Mô hình có vấn đề trong việc dự đoán lớp 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a418ea",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Nhóm xây dựng một mạng Netual network ứng dụng kỹ thuật trong học sâu như callbacks, đánh trọng số,.... Nhưng không khắc phục được tình trạng (imbalanced variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe10617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(prediction):\n",
    "    if isinstance(prediction, (np.ndarray, pd.Series)):\n",
    "        prediction = prediction.item()  # Hoặc sử dụng prediction[0] hoặc prediction.iloc[0]\n",
    "    if prediction==1:\n",
    "        return \"Y\"\n",
    "    else:\n",
    "        return \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b81715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(stt,model, X_test, Y_test):\n",
    "    print(f\"Lần thứ {stt}: \")\n",
    "    indx = rd.randint(0, X_test.shape[0] - 1)  # Đảm bảo indx nằm trong giới hạn của DataFrame\n",
    "    sample = X_test.iloc[indx, :].values        # Chuyển DataFrame thành mảng NumPy\n",
    "    sample = np.expand_dims(sample, axis=0)     # Mở rộng kích thước cho phù hợp với mô hình\n",
    "    y_predict = model.predict(sample)\n",
    "    print(y_predict)\n",
    "    Y_check = check_result(Y_test.iloc[indx])\n",
    "    print('True:', Y_check)\n",
    "    print('Predicted:', check_result(y_predict))\n",
    "    print(\"----------------------------\")\n",
    "    if Y_check==check_result(y_predict):\n",
    "        return True\n",
    "    else: return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "solandung=0\n",
    "hopdonggianlan=0\n",
    "for indx in range(len(x_test)):\n",
    "    sample = x_test.iloc[indx, :].values        # Chuyển DataFrame thành mảng NumPy\n",
    "    sample = np.expand_dims(sample, axis=0)     # Mở rộng kích thước cho phù hợp với mô hình\n",
    "    y_predict = model.predict(sample)\n",
    "    #print(y_predict[0][0])\n",
    "    Y_check = check_result(y_test.iloc[indx])\n",
    "    print('True:', Y_check)\n",
    "    print('Predicted:', check_result(y_predict))\n",
    "    print(\"----------------------------\")\n",
    "    if Y_check==check_result(y_predict):\n",
    "        solandung+=1\n",
    "        if Y_check=='Y':\n",
    "            hopdonggianlan+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a65590",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Số lần dự đoán đúng: {solandung} chiếm khoảng {(solandung/len(x_test))*100}% tổng lần dự đoán\")\n",
    "print(f\"Số hợp đồng gian lận trong lần kiểm tra: {hopdonggianlan} chiếm khoảng {(hopdonggianlan/len(y_test[y_test['fraud_reported']==1]))*100}% so với thực tế\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec44a6",
   "metadata": {},
   "source": [
    "* Ta có thể thấy trong tất cả các lần dự đoán, mô hình đều dự đoán 'N'(lớp 0). Đó là lí do tại sao chỉ số 'accuracy'lại cao như vậy ( vốn tập dữ liệu bị mất cân bằng lớp lớp 0 gấp 3 lần lớp 1)\n",
    "\n",
    "#### => Kết luận: Ta không dựa vào chỉ số 'accuracy' để đánh giá các mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d230486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fe14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169dd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aefbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
