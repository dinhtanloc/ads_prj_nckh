{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "478477c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 4778,
     "status": "ok",
     "timestamp": 1708077906703,
     "user": {
      "displayName": "Tấn Lộc Đinh",
      "userId": "14179370257782945104"
     },
     "user_tz": -420
    },
    "id": "dd8c11c0",
    "outputId": "934b372a-43b8-4e00-df99-4f13b5ef9a68"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from numpy import set_printoptions\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdcdb994",
   "metadata": {
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1708077986631,
     "user": {
      "displayName": "Tấn Lộc Đinh",
      "userId": "14179370257782945104"
     },
     "user_tz": -420
    },
    "id": "622aee0d"
   },
   "outputs": [],
   "source": [
    "exps_dir = \"../../exps\"\n",
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f\"{exps_dir}/feature1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd094b73",
   "metadata": {
    "id": "79d162d6"
   },
   "source": [
    "* kiểm tra và tạo các thư mục (nếu chưa có)\n",
    "* tập test 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79efd8a9",
   "metadata": {
    "id": "5cf7e092"
   },
   "source": [
    "# 5. Xây dựng và đánh giá mô hình học sâu Neutual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6c62652",
   "metadata": {
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1708078108071,
     "user": {
      "displayName": "Tấn Lộc Đinh",
      "userId": "14179370257782945104"
     },
     "user_tz": -420
    },
    "id": "d84bdb3c"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7af34f7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3125,
     "status": "ok",
     "timestamp": 1708078044932,
     "user": {
      "displayName": "Tấn Lộc Đinh",
      "userId": "14179370257782945104"
     },
     "user_tz": -420
    },
    "id": "2e81211d",
    "outputId": "55e92b37-0bda-4482-ab22-ed4bda89daf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{exps_dir}/feature1/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "514ab071",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1708078116830,
     "user": {
      "displayName": "Tấn Lộc Đinh",
      "userId": "14179370257782945104"
     },
     "user_tz": -420
    },
    "id": "6dda6290",
    "outputId": "eb6117ad-064d-4dd8-9080-ed61d2e285e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19f0f39f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1708078117141,
     "user": {
      "displayName": "Tấn Lộc Đinh",
      "userId": "14179370257782945104"
     },
     "user_tz": -420
    },
    "id": "f1c3ac7a",
    "outputId": "b25a0246-f0ff-43b8-c94a-62ccf57d2f17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba595b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud_reported']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "list(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bad8ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Dữ liệu label đã được mã hóa\n",
    "def oneHot(arr):\n",
    "    labels = np.array(arr)\n",
    "    \n",
    "    # Khởi tạo một trình chuyển đổi OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    \n",
    "    # Reshape lại dữ liệu labels để có dạng cột (cần là ma trận 2D)\n",
    "    labels_reshaped = labels.reshape(-1, 1)\n",
    "    \n",
    "    # Fit trình chuyển đổi vào dữ liệu\n",
    "    encoder.fit(labels_reshaped)\n",
    "    \n",
    "    # Chuyển đổi labels sang dạng one-hot encoding\n",
    "    onehot_labels = encoder.transform(labels_reshaped)\n",
    "    return onehot_labels\n",
    "\n",
    "y_check=oneHot(y_train)\n",
    "y_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6772070",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot=oneHot(y_train)\n",
    "y_test_onehot=oneHot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dab912",
   "metadata": {
    "id": "cb6de984"
   },
   "source": [
    "#### * Xây dựng model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70d5c653",
   "metadata": {
    "id": "b010fd4d",
    "outputId": "a0c5512e-31bf-46ce-810d-6fef5f23edd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Hyperparameters:\n",
      "{'n_estimators': 500, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Định nghĩa không gian siêu tham số\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_rf = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_rf.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Random Forest tốt nhất\n",
    "print(\"Best Random Forest Hyperparameters:\")\n",
    "print(random_search_rf.best_params_)\n",
    "n_estimators=random_search_rf.best_params_['n_estimators']\n",
    "max_depth=random_search_rf.best_params_['max_depth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb7af166",
   "metadata": {
    "id": "272653fe",
    "outputId": "3595ea23-56f8-4f47-be30-88e7eab7009a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree Hyperparameters:\n",
      "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 16, 'min_samples_split': 18, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Định nghĩa không gian siêu tham số cho Decision Tree\n",
    "param_dist_dt = {'criterion': ['gini', 'entropy'],\n",
    "                 'splitter': ['best', 'random'],\n",
    "                 'max_depth': randint(3, 10),\n",
    "                 'min_samples_split': randint(2, 20),\n",
    "                 'min_samples_leaf': randint(1, 20)}\n",
    "\n",
    "# Khởi tạo mô hình Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_dt = RandomizedSearchCV(dt_model, param_distributions=param_dist_dt, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_dt.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Decision Tree tốt nhất\n",
    "print(\"Best Decision Tree Hyperparameters:\")\n",
    "print(random_search_dt.best_params_)\n",
    "best_dt_model = random_search_dt.best_estimator_\n",
    "criterion=random_search_dt.best_params_['criterion']\n",
    "max_depthdt=random_search_dt.best_params_['max_depth']\n",
    "min_samples_leaf=random_search_dt.best_params_['min_samples_leaf']\n",
    "splitter=random_search_dt.best_params_['splitter']\n",
    "min_samples_split=random_search_dt.best_params_['min_samples_split']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03fa9ac2",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "error",
     "timestamp": 1708078131974,
     "user": {
      "displayName": "Tấn Lộc Đinh",
      "userId": "14179370257782945104"
     },
     "user_tz": -420
    },
    "id": "732f9456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 00m 31s]\n",
      "val_accuracy: 0.7333333492279053\n",
      "\n",
      "Best val_accuracy So Far: 0.7666666507720947\n",
      "Total elapsed time: 00h 13m 37s\n",
      "(None, 42, 1)\n",
      "Model: \"InceptionV2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 42, 1)]           0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 42, 288)           1152      \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 42, 288)           249120    \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 21, 288)           0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 21, 448)           387520    \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 21, 448)           602560    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 10, 448)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 10, 32)            43040     \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 10, 32)            3104      \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 10, 32)            3104      \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 5, 32)             0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 5, 224)            21728     \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 5, 224)            150752    \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 5, 224)            150752    \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 2, 224)            0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv1D)       (None, 2, 192)            129216    \n",
      "                                                                 \n",
      " block5_conv2 (Conv1D)       (None, 2, 192)            110784    \n",
      "                                                                 \n",
      " block5_conv3 (Conv1D)       (None, 2, 192)            110784    \n",
      "                                                                 \n",
      " block5_pool (MaxPooling1D)  (None, 1, 192)            0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 192)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 386       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1964002 (7.49 MB)\n",
      "Trainable params: 1964002 (7.49 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "lr=0.0001\n",
    "\n",
    "def build_model(hp):\n",
    "    input_shape =(42,1)\n",
    "    x_input = Input(shape=input_shape)\n",
    "    print(x_input.shape)\n",
    "\n",
    "    filters1 = hp.Int('filters1', min_value=32, max_value=512, step=32)\n",
    "    filters2 = hp.Int('filters2', min_value=32, max_value=512, step=32)\n",
    "    filters3 = hp.Int('filters3', min_value=32, max_value=512, step=32)\n",
    "    filters4 = hp.Int('filters4', min_value=32, max_value=512, step=32)\n",
    "    filters5 = hp.Int('filters5', min_value=32, max_value=512, step=32)\n",
    "    kernel_size = hp.Int('kernel_size', min_value=2, max_value=5, step=1)\n",
    "    dense_units = hp.Int('dense_units', min_value=128, max_value=4096, step=128)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv1D(filters1, kernel_size, activation='relu', padding='same', name='block1_conv1')(x_input)\n",
    "    x = Conv1D(filters1, kernel_size, activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(filters2, kernel_size, activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv1D(filters2, kernel_size, activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(filters3, kernel_size, activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(filters3, kernel_size, activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv1D(filters3, kernel_size, activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(filters4, kernel_size, activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(filters4, kernel_size, activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv1D(filters4, kernel_size, activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv1D(filters5, kernel_size, activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv1D(filters5, kernel_size, activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv1D(filters5, kernel_size, activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block5_pool')(x)\n",
    "\n",
    "    # x = Flatten(name='flatten')(x)\n",
    "    # x = Dense(dense_units, activation='relu', name='fc1')(x)\n",
    "    # x = Dense(dense_units, activation='relu', name='fc2')(x)\n",
    "    # x = Dense(1, activation='sigmoid', name='predictions')(x)  # Sigmoid for binary classification\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    #x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(2, activation='softmax', name='predictions')(x)  # Sigmoid for binary classification\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(x_input, x, name='InceptionV2')\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    min_lr=0.000001,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Tạo đối tượng RandomSearch tuner\n",
    "tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=12,executions_per_trial=1, directory='VGG16_test')\n",
    "\n",
    "# Tìm kiếm tham số tốt nhất\n",
    "tuner.search(x_train, y_train_onehot, epochs=600, validation_data=(x_test, y_test_onehot),callbacks=[early_stopping,lr_scheduler])\n",
    "\n",
    "# Lấy mô hình tốt nhất\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "755e9a0f",
   "metadata": {
    "id": "8917077b",
    "outputId": "e51b9a7a-2c21-4a9e-9a30-19a0ba1579bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filters1': 288,\n",
       " 'filters2': 448,\n",
       " 'filters3': 32,\n",
       " 'filters4': 224,\n",
       " 'filters5': 192,\n",
       " 'kernel_size': 3,\n",
       " 'dense_units': 1536,\n",
       " 'learning_rate': 0.001}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trials = tuner.oracle.get_best_trials(1)[0].hyperparameters.values\n",
    "best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12d56184",
   "metadata": {
    "id": "c31643d6",
    "outputId": "dffe80df-9243-4b2d-bca9-e3b0d5863735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 42, 1)\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "Model: \"InceptionV2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 42, 1)]           0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 42, 288)           1152      \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 42, 288)           249120    \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 21, 288)           0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 21, 448)           387520    \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 21, 448)           602560    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 10, 448)           0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 10, 32)            43040     \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 10, 32)            3104      \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 10, 32)            3104      \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 5, 32)             0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 5, 224)            21728     \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 5, 224)            150752    \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 5, 224)            150752    \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 2, 224)            0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv1D)       (None, 2, 192)            129216    \n",
      "                                                                 \n",
      " block5_conv2 (Conv1D)       (None, 2, 192)            110784    \n",
      "                                                                 \n",
      " block5_conv3 (Conv1D)       (None, 2, 192)            110784    \n",
      "                                                                 \n",
      " block5_pool (MaxPooling1D)  (None, 1, 192)            0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 192)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 386       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1964002 (7.49 MB)\n",
      "Trainable params: 1964002 (7.49 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d5bcc9f",
   "metadata": {
    "id": "33e3467b",
    "outputId": "d3055f47-f9d1-4e4a-f670-e1b04b034b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = best_model.predict(x_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91152cdd",
   "metadata": {
    "id": "ce3eb7f8",
    "outputId": "85f4e6b3-f401-46c6-cabc-8454700706b1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikeras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, BatchNormalization, Dropout\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscikeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikeras'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import numpy as np\n",
    "def create_keras_model():\n",
    "    input_shape =(4,1)\n",
    "    x_input = Input(shape=input_shape)\n",
    "\n",
    "    filters1 = 288\n",
    "    filters2 = 448\n",
    "    filters3 = 32\n",
    "    filters4 = 224\n",
    "    filters5 = 192\n",
    "    kernel_size = 3\n",
    "    dense_units = 1536\n",
    "    learning_rate =0.001\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv1D(filters1, kernel_size, activation='relu', padding='same', name='block1_conv1')(x_input)\n",
    "    x = Conv1D(filters1, kernel_size, activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(filters2, kernel_size, activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv1D(filters2, kernel_size, activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(filters3, kernel_size, activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(filters3, kernel_size, activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv1D(filters3, kernel_size, activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(filters4, kernel_size, activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(filters4, kernel_size, activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv1D(filters4, kernel_size, activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv1D(filters5, kernel_size, activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv1D(filters5, kernel_size, activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv1D(filters5, kernel_size, activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling1D(2, strides=2, name='block5_pool')(x)\n",
    "\n",
    "    # x = Flatten(name='flatten')(x)\n",
    "    # x = Dense(dense_units, activation='relu', name='fc1')(x)\n",
    "    # x = Dense(dense_units, activation='relu', name='fc2')(x)\n",
    "    # x = Dense(1, activation='sigmoid', name='predictions')(x)  # Sigmoid for binary classification\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    #x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(2, activation='softmax', name='predictions')(x)  # Sigmoid for binary classification\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(x_input, x, name='InceptionV2')\n",
    "    # Thêm các lớp khác vào đây\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# keras_clf = KerasClassifier(build_fn=create_keras_model, epochs=10)\n",
    "rf_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "dtc_model=DecisionTreeClassifier(criterion=criterion,max_depth=max_depthdt,min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split,splitter=splitter)\n",
    "# Huấn luyện các mô hình cơ sở\n",
    "rf_model.fit(x_train, y_train)\n",
    "dtc_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Dự đoán đầu ra của các mô hình cơ sở\n",
    "rf_pred = rf_model.predict(x_test)\n",
    "dtc_pred = dtc_model.predict(x_test)\n",
    "\n",
    "\n",
    "# keras_pred = keras_clf.predict(x_test)\n",
    "stacked_input = np.column_stack((rf_pred,dtc_pred))\n",
    "\n",
    "\n",
    "#history=model.fit(x=x_train,y=y_train,\n",
    "          #validation_data=(x_test,y_test),class_weight=class_weights_dict ,\n",
    "          #batch_size=64,epochs=120, callbacks=[confusion_matrix_callback])\n",
    "\n",
    "keras_clf = KerasClassifier(build_fn=create_keras_model,batch_size=64,epochs=120,callbacks=[early_stopping,lr_scheduler])\n",
    "\n",
    "# Clone lại để tránh thay đổi trực tiếp vào mô hình gốc\n",
    "keras_clf = clone(keras_clf)\n",
    "\n",
    "# Xây dựng mô hình stacking\n",
    "stacked_model = StackingClassifier(\n",
    "    classifiers=[rf_model, dtc_model],\n",
    "    meta_classifier=keras_clf\n",
    ")\n",
    "\n",
    "# Tiếp tục với việc huấn luyện và đánh giá mô hình stacking\n",
    "stacked_model.fit(stacked_input, y_test)\n",
    "stacked_pred = stacked_model.predict(stacked_input)\n",
    "stacked_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1cada",
   "metadata": {
    "id": "7ca644b3",
    "outputId": "9addeaca-ae9c-4f67-c0fc-85d7d8eccd5c"
   },
   "outputs": [],
   "source": [
    "def VotingClassifier(result):\n",
    "    predictions_stack = np.vstack(result)\n",
    "    majority_votes = np.sum(predictions_stack, axis=0) >= (predictions_stack.shape[0] / 2)\n",
    "    return majority_votes.astype(int)\n",
    "predictions = VotingClassifier([predictions_model1, predictions_model4, predictions_model5])\n",
    "\n",
    "predictions.shape\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"Ensemble Voting Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e333f",
   "metadata": {
    "id": "9a1b5b98",
    "outputId": "eb519a1e-7796-495c-9760-aac08af9e1d2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Đánh giá độ chính xác\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Hiển thị báo cáo phân loại\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions,labels=[1,0]))\n",
    "\n",
    "# # Hiển thị ma trận nhầm lẫn\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred,labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b171ef8",
   "metadata": {
    "id": "b7819b55",
    "outputId": "708b791a-1f4d-4da4-e31d-d972825fd29f"
   },
   "outputs": [],
   "source": [
    "# Tính ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_test, predictions,labels=[1,0])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=[1,0], yticklabels=[1,0])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15218b4",
   "metadata": {
    "id": "1e5791c2"
   },
   "outputs": [],
   "source": [
    "def check_result(prediction):\n",
    "    prediction = (prediction > 0.5).astype(int)\n",
    "    if isinstance(prediction, (np.ndarray, pd.Series)):\n",
    "        prediction = prediction.item()  # Hoặc sử dụng prediction[0] hoặc prediction.iloc[0]\n",
    "    if prediction==1:\n",
    "        return \"Y\"\n",
    "    else:\n",
    "        return \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31937725",
   "metadata": {
    "id": "bdb04fa4",
    "outputId": "e399a015-8dba-4653-ef11-a15dd6037152"
   },
   "outputs": [],
   "source": [
    "solandung=0\n",
    "hopdonggianlan=0\n",
    "for indx in range(len(x_test)):\n",
    "    y_predict = predictions\n",
    "    #print(y_predict[0][0])\n",
    "    Y_check = check_result(y_test.iloc[indx])\n",
    "    print('True:', Y_check)\n",
    "    print('Predicted:', check_result(y_predict[indx]))\n",
    "    print(\"----------------------------\")\n",
    "    if Y_check==check_result(y_predict[indx]):\n",
    "        solandung+=1\n",
    "        if Y_check=='Y':\n",
    "            hopdonggianlan+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef68fa9",
   "metadata": {
    "id": "de1ecd0f",
    "outputId": "8375ad62-13d3-4f03-ca7f-d8802b11ddaf"
   },
   "outputs": [],
   "source": [
    "print(f\"Số lần dự đoán đúng: {solandung} chiếm khoảng {(solandung/len(x_test))*100}% tổng lần dự đoán\")\n",
    "print(f\"Số hợp đồng gian lận trong lần kiểm tra: {hopdonggianlan} chiếm khoảng {(hopdonggianlan/len(y_test[y_test['fraud_reported']==1]))*100}% so với thực tế\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce64eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
