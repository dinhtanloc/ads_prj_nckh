{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c3a4fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_1\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [1024], output_shape = [700, 42, 1]\n\nCall arguments received by layer \"reshape_1\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 1024), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 131\u001b[0m\n\u001b[0;32m    126\u001b[0m     x \u001b[38;5;241m=\u001b[39m BatchNormalization(axis\u001b[38;5;241m=\u001b[39mchannel_axis, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv_pw_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_bn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m block_id)(x)\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv_pw_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_relu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m block_id)(x)\n\u001b[1;32m--> 131\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mMobileNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m model\u001b[38;5;241m.\u001b[39msummary\n",
      "Cell \u001b[1;32mIn[14], line 86\u001b[0m, in \u001b[0;36mMobileNet\u001b[1;34m(input_shape, alpha, depth_multiplier, dropout, classes)\u001b[0m\n\u001b[0;32m     84\u001b[0m shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m700\u001b[39m, \u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Adjust the shape based on your requirements\u001b[39;00m\n\u001b[0;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m GlobalAveragePooling1D()(x)\n\u001b[1;32m---> 86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(dropout, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m     88\u001b[0m x \u001b[38;5;241m=\u001b[39m Conv1D(classes, \u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv_preds\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\keras\\layers\\reshaping\\reshape.py:118\u001b[0m, in \u001b[0;36mReshape._fix_unknown_dimension\u001b[1;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[0;32m    116\u001b[0m     output_shape[unknown] \u001b[38;5;241m=\u001b[39m original \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m known\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original \u001b[38;5;241m!=\u001b[39m known:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_shape\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_1\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [1024], output_shape = [700, 42, 1]\n\nCall arguments received by layer \"reshape_1\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 1024), dtype=float32)"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, GlobalAveragePooling1D,AveragePooling1D,Concatenate, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "class DepthwiseConv1D(Layer):\n",
    "    def __init__(self, kernel_size, depth_multiplier=1, strides=1, padding='valid', **kwargs):\n",
    "        super(DepthwiseConv1D, self).__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 3:\n",
    "            raise ValueError('Input shape should be a tuple of 3 dimensions.')\n",
    "        input_dim = input_shape[2]\n",
    "        depthwise_kernel_shape = (self.kernel_size, input_dim, self.depth_multiplier)\n",
    "\n",
    "        self.depthwise_kernel = self.add_weight(shape=depthwise_kernel_shape,\n",
    "                                                initializer='glorot_uniform',\n",
    "                                                name='depthwise_kernel')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        length = input_shape[1]\n",
    "        if self.padding == 'valid':\n",
    "            length -= self.kernel_size - 1\n",
    "        length = (length + self.strides - 1) // self.strides\n",
    "\n",
    "        return (input_shape[0], length, input_shape[2] * self.depth_multiplier)\n",
    "\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def MobileNet(input_shape=None,\n",
    "              alpha=1.0,\n",
    "              depth_multiplier=1,\n",
    "              dropout=1e-3,\n",
    "              classes=1):\n",
    "    input_shape=(700,42)\n",
    "    x_input = Input(shape=input_shape)\n",
    "    x = _conv_block(x_input, 32, alpha, strides=2)\n",
    "    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier,\n",
    "                              strides=2, block_id=2)\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier,\n",
    "                              strides=2, block_id=4)\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier,\n",
    "                              strides=2, block_id=6)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier,\n",
    "                              strides=2, block_id=12)\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n",
    "    shape = (700, 42, 1)  # Adjust the shape based on your requirements\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Reshape(shape, name='reshape_1')(x)\n",
    "    x = Dropout(dropout, name='dropout')(x)\n",
    "    x = Conv1D(classes, 1, padding='same', name='conv_preds')(x)\n",
    "    x = Activation('softmax', name='act_softmax')(x)\n",
    "    x = Reshape((700, 42), name='reshape_2')(x)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _conv_block(inputs, filters, alpha, kernel=3, strides=1):\n",
    "    channel_axis = 1 \n",
    "    filters = int(filters * alpha)\n",
    "    x = Conv1D(filters, kernel,\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               strides=strides,\n",
    "               name='conv1')(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis, name='conv1_bn')(x)\n",
    "    return Activation('relu', name='conv1_relu')(x)\n",
    "\n",
    "\n",
    "def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n",
    "                          depth_multiplier=1, strides=1, block_id=1):\n",
    "    channel_axis = 1\n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "\n",
    "    x = DepthwiseConv1D(3,\n",
    "                        padding='same',\n",
    "                        depth_multiplier=depth_multiplier,\n",
    "                        strides=strides,\n",
    "                        name='conv_dw_%d' % block_id)(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n",
    "    x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n",
    "\n",
    "    x = Conv1D(pointwise_conv_filters, 1,\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               strides=1,\n",
    "               name='conv_pw_%d' % block_id)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % block_id)(x)\n",
    "    return Activation('relu', name='conv_pw_%d_relu' % block_id)(x)\n",
    "\n",
    "\n",
    "\n",
    "model=MobileNet()\n",
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4a905f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 42, 1)\n",
      "(None, 1, 1024)\n",
      "(None, 1, 1)\n",
      "Model: \"mobilenet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 42, 1)]           0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 21, 32)            96        \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 21, 32)           84        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (Activation)     (None, 21, 32)            0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv1D)  (None, 21, 32)           96        \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 21, 32)           84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (Activation)  (None, 21, 32)           0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv1D)          (None, 21, 64)            2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 21, 64)           84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (Activation)  (None, 21, 64)           0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv1D)  (None, 21, 64)           192       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 21, 64)           84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (Activation)  (None, 21, 64)           0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv1D)          (None, 21, 128)           8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 21, 128)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (Activation)  (None, 21, 128)          0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv1D)  (None, 21, 128)          384       \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 21, 128)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (Activation)  (None, 21, 128)          0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv1D)          (None, 21, 128)           16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 21, 128)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (Activation)  (None, 21, 128)          0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv1D)  (None, 21, 128)          384       \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 21, 128)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (Activation)  (None, 21, 128)          0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv1D)          (None, 21, 256)           32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 21, 256)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (Activation)  (None, 21, 256)          0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv1D)  (None, 21, 256)          768       \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 21, 256)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (Activation)  (None, 21, 256)          0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv1D)          (None, 21, 256)           65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 21, 256)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (Activation)  (None, 21, 256)          0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv1D)  (None, 21, 256)          768       \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 21, 256)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (Activation)  (None, 21, 256)          0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv1D)          (None, 21, 512)           131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv1D)  (None, 21, 512)          1536      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv1D)          (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv1D)  (None, 21, 512)          1536      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv1D)          (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv_dw_9 (DepthwiseConv1D)  (None, 21, 512)          1536      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv1D)          (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv1D  (None, 21, 512)          1536      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_pw_10 (Conv1D)         (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv1D  (None, 21, 512)          1536      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_pw_11 (Conv1D)         (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv1D  (None, 21, 512)          1536      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_pw_12 (Conv1D)         (None, 21, 1024)          524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 21, 1024)         84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (Activation  (None, 21, 1024)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv1D  (None, 21, 1024)         3072      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 21, 1024)         84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (Activation  (None, 21, 1024)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_pw_13 (Conv1D)         (None, 21, 1024)          1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 21, 1024)         84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (Activation  (None, 21, 1024)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 1024)             0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 1, 1024)           0         \n",
      "                                                                 \n",
      " conv_preds (Conv1D)         (None, 1, 1)              1025      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1, 1)              0         \n",
      "                                                                 \n",
      " act_softmax (Activation)    (None, 1, 1)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,157,853\n",
      "Trainable params: 3,156,719\n",
      "Non-trainable params: 1,134\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, Reshape, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class DepthwiseConv1D(Layer):\n",
    "    def __init__(self, kernel_size, depth_multiplier=1, strides=1, padding='valid', **kwargs):\n",
    "        super(DepthwiseConv1D, self).__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 3:\n",
    "            raise ValueError('Input shape should be a tuple of 3 dimensions.')\n",
    "        input_dim = input_shape[2]\n",
    "        depthwise_kernel_shape = (self.kernel_size, input_dim, self.depth_multiplier)\n",
    "\n",
    "        self.depthwise_kernel = self.add_weight(shape=depthwise_kernel_shape,\n",
    "                                                initializer='glorot_uniform',\n",
    "                                                name='depthwise_kernel')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        length = input_shape[1]\n",
    "        if self.padding == 'valid':\n",
    "            length -= self.kernel_size - 1\n",
    "        length = (length + self.strides - 1) // self.strides\n",
    "\n",
    "        return (input_shape[0], length, input_shape[2] * self.depth_multiplier)\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "    return x\n",
    "\n",
    "def MobileNet(input_shape=None, alpha=1.0, depth_multiplier=1, dropout=1e-3, classes=1):\n",
    "    input_shape = (42,1)\n",
    "    x_input = Input(shape=input_shape)\n",
    "    print(x_input.shape)\n",
    "    x = _conv_block(x_input, 32, alpha, strides=2)\n",
    "    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, strides=2, block_id=2)\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, strides=2, block_id=4)\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, strides=2, block_id=6)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, strides=2, block_id=12)\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout, name='dropout')(x)\n",
    "    x = Reshape((1, 1024))(x)\n",
    "    print(x.shape)\n",
    "    x = Conv1D(classes, 1, padding='same', name='conv_preds')(x)\n",
    "    print(x.shape)\n",
    "    x = Reshape((1,1), name='reshape_2')(x)\n",
    "    x = Activation('softmax', name='act_softmax')(x)\n",
    "    model = Model(inputs=x_input, outputs=x, name='mobilenet')\n",
    "    return model\n",
    "\n",
    "def _conv_block(inputs, filters, alpha, kernel=3, strides=1):\n",
    "    channel_axis = 1\n",
    "    filters = int(filters * alpha)\n",
    "    x = Conv1D(filters, kernel,\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               strides=strides,\n",
    "               name='conv1')(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis, name='conv1_bn')(x)\n",
    "    return Activation('relu', name='conv1_relu')(x)\n",
    "\n",
    "def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n",
    "                          depth_multiplier=1, strides=1, block_id=1):\n",
    "    channel_axis = 1\n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "\n",
    "    x = DepthwiseConv1D(3,\n",
    "                        padding='same',\n",
    "                        depth_multiplier=depth_multiplier,\n",
    "                        strides=strides,\n",
    "                        name='conv_dw_%d' % block_id)(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n",
    "    x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n",
    "\n",
    "    x = Conv1D(pointwise_conv_filters, 1,\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               strides=1,\n",
    "               name='conv_pw_%d' % block_id)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % block_id)(x)\n",
    "    return Activation('relu', name='conv_pw_%d_relu' % block_id)(x)\n",
    "\n",
    "model = MobileNet()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cbceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
